{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: MIT-0\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "env_path = Path('..') / 'environmentsettings.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "skin_cancer_bucket=os.environ.get('SKIN_CANCER_BUCKET')\n",
    "skin_cancer_bucket_path=os.environ.get('SKIN_CANCER_BUCKET_PATH')\n",
    "skin_cancer_files=os.environ.get('SKIN_CANCER_FILES')\n",
    "skin_cancer_files_ext=os.environ.get('SKIN_CANCER_FILES_EXT')\n",
    "base_dir = os.environ.get('BASE_DIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "if os.path.exists(os.path.join(base_dir,skin_cancer_files)):\n",
    "    shutil.rmtree(base_dir+skin_cancer_files)\n",
    "    \n",
    "if os.path.exists(os.path.join(base_dir,skin_cancer_files_ext)):\n",
    "    os.remove(os.path.join(base_dir,skin_cancer_files_ext))    \n",
    "\n",
    "datafolder = os.path.join(base_dir,'HAM10000')\n",
    "\n",
    "if os.path.exists(os.path.join(base_dir,'HAM10000.tar.gz')):\n",
    "    os.remove(os.path.join(base_dir,'HAM10000.tar.gz'))\n",
    "\n",
    "if os.path.exists(datafolder):\n",
    "    shutil.rmtree(datafolder)\n",
    "    \n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(skin_cancer_bucket, skin_cancer_bucket_path+'/'+skin_cancer_files_ext,base_dir+skin_cancer_files_ext)\n",
    "\n",
    "print('we are doing download dataset from  ours3 bucket '+skin_cancer_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from numpy.random import seed\n",
    "seed(101)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.mkdir(base_dir+skin_cancer_files)\n",
    "os.mkdir(base_dir+skin_cancer_files+'/HAM_images_part_1')\n",
    "os.mkdir(base_dir+skin_cancer_files+'/HAM_images_part_2')\n",
    "\n",
    "print('extract dataset for modle train and transform.')\n",
    "\n",
    "torchtext.utils.extract_archive(base_dir+skin_cancer_files_ext, base_dir+skin_cancer_files)\n",
    "torchtext.utils.extract_archive(base_dir+skin_cancer_files+'/HAM10000_images_part_1.zip', base_dir+skin_cancer_files+'/HAM_images_part_1')\n",
    "torchtext.utils.extract_archive(base_dir+skin_cancer_files+'/HAM10000_images_part_2.zip', base_dir+skin_cancer_files+'/HAM_images_part_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(datafolder)\n",
    "\n",
    "folderfortrain = os.path.join(datafolder, 'folderfortrain')\n",
    "os.mkdir(folderfortrain)\n",
    "\n",
    "validfolder = os.path.join(datafolder, 'validfolder')\n",
    "os.mkdir(validfolder)\n",
    "\n",
    "print('Create training and validation folder under directory HAM10000')\n",
    "\n",
    "nv = os.path.join(folderfortrain, 'nv')\n",
    "os.mkdir(nv)\n",
    "mel = os.path.join(folderfortrain, 'mel')\n",
    "os.mkdir(mel)\n",
    "bkl = os.path.join(folderfortrain, 'bkl')\n",
    "os.mkdir(bkl)\n",
    "bcc = os.path.join(folderfortrain, 'bcc')\n",
    "os.mkdir(bcc)\n",
    "akiec = os.path.join(folderfortrain, 'akiec')\n",
    "os.mkdir(akiec)\n",
    "vasc = os.path.join(folderfortrain, 'vasc')\n",
    "os.mkdir(vasc)\n",
    "datafolder = os.path.join(folderfortrain, 'datafolder')\n",
    "os.mkdir(datafolder)\n",
    "\n",
    "nv = os.path.join(validfolder, 'nv')\n",
    "os.mkdir(nv)\n",
    "mel = os.path.join(validfolder, 'mel')\n",
    "os.mkdir(mel)\n",
    "bkl = os.path.join(validfolder, 'bkl')\n",
    "os.mkdir(bkl)\n",
    "bcc = os.path.join(validfolder, 'bcc')\n",
    "os.mkdir(bcc)\n",
    "akiec = os.path.join(validfolder, 'akiec')\n",
    "os.mkdir(akiec)\n",
    "vasc = os.path.join(validfolder, 'vasc')\n",
    "os.mkdir(vasc)\n",
    "datafolder = os.path.join(validfolder, 'datafolder')\n",
    "os.mkdir(datafolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafeed = pd.read_csv(base_dir+skin_cancer_files+'/HAM10000_metadata')\n",
    "datafeed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = datafeed.groupby('lesion_id').count()\n",
    "datafolder = datafolder[datafolder['image_id'] == 1]\n",
    "datafolder.reset_index(inplace=True)\n",
    "datafolder.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_duplicates(x):\n",
    "   \n",
    "    unique_list = list(datafolder['lesion_id'])\n",
    "    \n",
    "    if x in unique_list:\n",
    "        return 'unique_data'\n",
    "    else:\n",
    "        return 'duplicates'\n",
    "    \n",
    "datafeed['duplicates'] = datafeed['lesion_id']\n",
    "datafeed['duplicates'] = datafeed['duplicates'].apply(identify_duplicates)\n",
    "datafeed.head()\n",
    "print('we have removed duplicates')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafeed['duplicates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = datafeed[datafeed['duplicates'] == 'unique_data']\n",
    "datafolder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = datafolder['dx']\n",
    "_, df_val = train_test_split(datafolder, test_size=0.17, random_state=101, stratify=y)\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_val_rows(x):\n",
    "    valiList = list(df_val['image_id'])\n",
    "    \n",
    "    if str(x) in valiList:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "datafeed['train_or_val'] = datafeed['image_id']\n",
    "datafeed['train_or_val'] = datafeed['train_or_val'].apply(identify_val_rows)\n",
    "df_train = datafeed[datafeed['train_or_val'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafeed.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "HAM1 = os.listdir(base_dir+skin_cancer_files+'/HAM_images_part_1')\n",
    "HAM2 = os.listdir(base_dir+skin_cancer_files+'/HAM_images_part_2')\n",
    "train_list = list(df_train['image_id'])\n",
    "valiList = list(df_val['image_id'])\n",
    "\n",
    "# we are transfering the trained images\n",
    "print('Sort Pictures by Type of Skin Cancer')\n",
    "\n",
    "for pictire in train_list:\n",
    "    \n",
    "    fname = pictire + '.jpg'\n",
    "    label = datafeed.loc[pictire,'dx']\n",
    "    \n",
    "    if fname in HAM1:        \n",
    "        src = os.path.join(base_dir+skin_cancer_files+'/HAM_images_part_1', fname)        \n",
    "        dst = os.path.join(folderfortrain, label, fname)        \n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    if fname in HAM2:        \n",
    "        src = os.path.join(base_dir+skin_cancer_files+'/HAM_images_part_2', fname)        \n",
    "        dst = os.path.join(folderfortrain, label, fname)        \n",
    "        shutil.copyfile(src, dst)\n",
    "        \n",
    "for pictire in valiList:\n",
    "    \n",
    "    fname = pictire + '.jpg'\n",
    "    label = datafeed.loc[pictire,'dx']\n",
    "    \n",
    "    if fname in HAM1:        \n",
    "        src = os.path.join(base_dir+skin_cancer_files+'/HAM_images_part_1', fname)        \n",
    "        dst = os.path.join(validfolder, label, fname)        \n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    if fname in HAM2:        \n",
    "        src = os.path.join(base_dir+skin_cancer_files+'/HAM_images_part_2', fname)        \n",
    "        dst = os.path.join(validfolder, label, fname)        \n",
    "        shutil.copyfile(src, dst)\n",
    "        \n",
    "print('Images sorted by their Classes')\n",
    "print('nv: '+str(len(os.listdir(folderfortrain +'/nv'))))\n",
    "print('mel: '+str(len(os.listdir(folderfortrain +'/mel'))))\n",
    "print('bkl: '+str(len(os.listdir(folderfortrain +'/bkl'))))\n",
    "print('bcc: '+str(len(os.listdir(folderfortrain +'/bcc'))))\n",
    "print('akiec: '+str(len(os.listdir(folderfortrain +'/akiec'))))\n",
    "print('vasc: '+str(len(os.listdir(folderfortrain +'/vasc'))))\n",
    "print('datafolder: '+str(len(os.listdir(folderfortrain +'/datafolder'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classList = ['mel','bkl','bcc','akiec','vasc','datafolder']\n",
    "print('Expand Pictures Via Class')\n",
    "\n",
    "for item in classList:        \n",
    "    aug_dir = datafolder + '/aug_dir'\n",
    "    os.mkdir(aug_dir)    \n",
    "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
    "    os.mkdir(img_dir)\n",
    "    \n",
    "    img_class = item\n",
    "\n",
    "    img_list = os.listdir(folderfortrain + '/'+ img_class)\n",
    "    \n",
    "    for fname in img_list:\n",
    "        src = os.path.join(folderfortrain + '/' + img_class, fname)\n",
    "        dst = os.path.join(img_dir,fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "        \n",
    "    aug_list = os.listdir(img_dir)\n",
    "    \n",
    "    num_aug_images_wanted = 5000\n",
    "    num_files = len(os.listdir(img_dir))\n",
    "    num_batches = int(np.ceil((num_aug_images_wanted/num_files)))\n",
    "    \n",
    "    j = 0\n",
    "    for i in range(1,num_batches):\n",
    "        for fname in aug_list:\n",
    "            src = os.path.join(img_dir, fname)\n",
    "            dst = os.path.join(folderfortrain + '/' + img_class, 'AUG_' + str(j) + '_'+ fname)\n",
    "            shutil.copyfile(src, dst)\n",
    "        j = j + 1\n",
    "            \n",
    "    shutil.rmtree(aug_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Class-Based Images Following Augmentation')\n",
    "print('nv: '+str(len(os.listdir(folderfortrain +'/nv'))))\n",
    "print('mel: '+str(len(os.listdir(folderfortrain +'/mel'))))\n",
    "print('bkl: '+str(len(os.listdir(folderfortrain +'/bkl'))))\n",
    "print('bcc: '+str(len(os.listdir(folderfortrain +'/bcc'))))\n",
    "print('akiec: '+str(len(os.listdir(folderfortrain +'/akiec'))))\n",
    "print('vasc: '+str(len(os.listdir(folderfortrain +'/vasc'))))\n",
    "print('datafolder: '+str(len(os.listdir(folderfortrain +'/datafolder'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class_names = sorted([x for x in os.listdir(folderfortrain) if os.path.isdir(os.path.join(folderfortrain, x))])\n",
    "num_class = len(class_names)\n",
    "image_files = [[os.path.join(folderfortrain, class_name, x) \n",
    "                for x in os.listdir(os.path.join(folderfortrain, class_name))] \n",
    "               for class_name in class_names]\n",
    "image_file_list = []\n",
    "image_label_list = []\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    image_file_list.extend(image_files[i])\n",
    "    image_label_list.extend([i] * len(image_files[i]))\n",
    "num_total = len(image_label_list)\n",
    "image_width, image_height = Image.open(image_file_list[0]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('A Sample of Image Training')\n",
    "plt.subplots(3, 3, figsize=(8, 8))\n",
    "for i,k in enumerate(np.random.randint(num_total, size=9)):\n",
    "    im = Image.open(image_file_list[k])\n",
    "    arr = np.array(im)\n",
    "    #print(arr.shape)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.xlabel(class_names[image_label_list[k]])\n",
    "    plt.imshow(arr, vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Total image count:', num_total)\n",
    "print('Image dimensions:', image_width, \"x\", image_height)\n",
    "print('Label names:', class_names)\n",
    "print('Label counts:', [len(image_files[i]) for i in range(num_class)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('HAM10000 data set transformation and compression.')\n",
    "!tar -czf ../HAM10000.tar.gz ../HAM10000\n",
    "print('Transformation of the training dataset is finished.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
